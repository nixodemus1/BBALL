{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcyfvshEB8jDEKsBBvjgjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nixodemus1/BBALL/blob/Nicks_Branch/BBALL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Check to make sure pytorch and CUDA is installed. this is fine if your running it via collaborate, but this needs to be checked before we attempt to use it nativly on your computer"
      ],
      "metadata": {
        "id": "byysDcFL9a-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import visualization library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Verify PyTorch version\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "bdvhbweu9rnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check is cuda is installed in the gpu, otherwise just use the cpu"
      ],
      "metadata": {
        "id": "kxIa1gxx90cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if we have a GPU to use for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('A {} device was detected.'.format(device))\n",
        "\n",
        "# Print the name of the cuda device, if detected\n",
        "if device=='cuda':\n",
        "    print (torch.cuda.get_device_name(device=device))"
      ],
      "metadata": {
        "id": "-vnXE_vt97Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "part 2: download and prepair our datasets."
      ],
      "metadata": {
        "id": "spMaJib-9--K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Pandas to do our dataprocessing on the dataset\n",
        "# Download the dataset\n",
        "import pandas as pd\n",
        "url = 'https://github.com/nixodemus1/BBALL/blob/3cc57ed022bb208622ececb1599736f61d4004f5/data/Final_dataset.csv#L1'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Explore the first 5 rows of the dataset\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "7nfm78iU-Fu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we now have the final dataset provided by ish loaded and ready to be looked at my the neural network. next problem is then standardizing a lot of the data since it will be hard for the nn to work otherwise. first we are gonna be using SVC so we should see what it does to standardize its data. however, lets first see how big this data is"
      ],
      "metadata": {
        "id": "GreeH6G3yfYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the size/shape of our dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "pgghUQ4azJBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "oh."
      ],
      "metadata": {
        "id": "gwwic1z7zRWo"
      }
    }
  ]
}